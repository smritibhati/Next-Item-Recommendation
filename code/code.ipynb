{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"reviews_Baby_5.json/datawithcomma\"\n",
    "jsonfile = open(datafile)\n",
    "data = json.load(jsonfile)\n",
    "userlist ={x['reviewerID']:[] for x in data}\n",
    "# uniqreviewer = list(set(reviewerIds))\n",
    "\n",
    "userlist1 = list(map(lambda item:userlist[item[\"reviewerID\"]].append((item[\"asin\"],item[\"unixReviewTime\"])),data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19445\n",
      "4382\n"
     ]
    }
   ],
   "source": [
    "removelist = [k for k in userlist if len(userlist[k]) < 10]\n",
    "\n",
    "i=0\n",
    "itemset=set()\n",
    "print(len(userlist))\n",
    "for key in removelist:\n",
    "    del userlist[key]\n",
    "for k in userlist:    \n",
    "    userlist[k].sort(key = lambda x:x[1])\n",
    "#     print(userlist[k][:][0])\n",
    "    itemset = itemset.union(set([a for (a,b) in userlist[k]]))\n",
    "    \n",
    "print(len(userlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encodedict = {val:idx for idx,val in enumerate(list(itemset),start=1)}\n",
    "\n",
    "# print(encodedict)\n",
    "\n",
    "# featurevector = [[encodedict[x] for (x,y) in useritems] for useritems in userlist.values()]\n",
    "featurevector=[]\n",
    "maxlen = 0\n",
    "for userseq in userlist.values():\n",
    "#     featurevector.append([])\n",
    "    (featurevector.append([encodedict[x] for (x,y) in userseq]))\n",
    "    if len(featurevector[-1]) > maxlen:\n",
    "        maxlen = len(featurevector[-1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# the number of possible words in the vocabulary, here 1000 (1 + maximum word index),\n",
    "# and the dimensionality of the embeddings, here 32.\n",
    "embedding_dim=32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(featurevector,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 608 3290 4511 2484 1339 4464 4038 5214 4919 1967 6720    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mythri/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 125, 32)           220256    \n",
      "=================================================================\n",
      "Total params: 220,256\n",
      "Trainable params: 220,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(len(itemset), embedding_dim, input_length=maxlen)\n",
    "  \n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating   timestamp  user_id  item_id\n",
      "565289     5.0  1402272000        0    28438\n",
      "661829     5.0  1402272000        0    35116\n",
      "706586     5.0  1404432000        1    38846\n",
      "114426     5.0  1363996800        2     2778\n",
      "857429     3.0  1395619200        3    53525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "filename = 'ratings_Baby.csv'\n",
    "\n",
    "df = pd.read_csv(filename,names=['userid','itemid','rating','timestamp'])\n",
    "userset = np.unique(df.iloc[:,0].values)\n",
    "itemset = np.unique(df.iloc[:,1].values)\n",
    "userdict = {userset[i]:i for i in range(len(userset))}\n",
    "itemdict = {itemset[i]:i for i in range(len(itemset))}\n",
    "df['user_id']= df.apply(lambda row : userdict[row.userid],axis=1)\n",
    "df['item_id']= df.apply(lambda row : itemdict[row.itemid],axis=1)\n",
    "df = df.drop(columns=['userid','itemid'])\n",
    "df = df.sort_values(['user_id','timestamp'],ascending=[True,True])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating   timestamp  user_id  item_id\n",
      "565289     5.0  1402272000        0    28438\n",
      "661829     5.0  1402272000        0    35116\n",
      "706586     5.0  1404432000        1    38846\n",
      "114426     5.0  1363996800        2     2778\n",
      "857429     3.0  1395619200        3    53525\n",
      "830052     5.0  1404259200        3    50755\n",
      "558474     4.0  1381363200        4    27981\n",
      "438858     4.0  1402617600        4    20593\n",
      "781486     5.0  1402617600        4    44982\n",
      "869648     5.0  1402617600        4    55421\n",
      "900485     5.0  1402617600        4    60787\n",
      "422794     3.0  1404259200        4    19679\n",
      "663457     5.0  1404259200        4    35230\n",
      "907036     3.0  1404259200        4    62145\n",
      "853569     3.0  1405209600        4    53078\n",
      "763901     5.0  1363651200        5    43161\n",
      "76675      4.0  1387411200        5     1489\n",
      "434713     4.0  1387411200        5    20347\n",
      "547713     5.0  1354233600        6    27202\n",
      "800569     5.0  1370304000        7    47210\n",
      "490426     5.0  1403654400        8    23446\n",
      "438191     5.0  1374364800        9    20579\n",
      "786318     5.0  1358726400       10    45525\n",
      "402697     5.0  1355616000       11    18351\n",
      "579288     5.0  1355616000       11    29135\n",
      "635946     5.0  1355616000       11    32864\n",
      "839711     5.0  1397520000       12    51765\n",
      "439584     5.0  1392681600       13    20596\n",
      "368923     1.0  1361750400       14    15958\n",
      "573368     4.0  1372204800       15    28868\n",
      "688645     2.0  1392076800       16    37122\n",
      "201435     2.0  1396569600       17     6765\n",
      "626912     1.0  1375833600       18    32216\n",
      "180878     5.0  1395273600       19     5898\n",
      "704852     5.0  1405296000       20    38697\n",
      "151348     4.0  1376006400       21     4396\n",
      "761573     5.0  1388448000       21    42857\n",
      "712248     5.0  1397001600       21    39341\n",
      "310559     5.0  1404345600       21    12930\n",
      "666249     1.0  1404345600       21    35451\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0:40,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
