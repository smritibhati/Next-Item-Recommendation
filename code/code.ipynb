{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"reviews_Baby_5.json/datawithcomma\"\n",
    "jsonfile = open(datafile)\n",
    "data = json.load(jsonfile)\n",
    "userlist ={x['reviewerID']:[] for x in data}\n",
    "# uniqreviewer = list(set(reviewerIds))\n",
    "\n",
    "userlist1 = list(map(lambda item:userlist[item[\"reviewerID\"]].append((item[\"asin\"],item[\"unixReviewTime\"])),data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19445\n",
      "4382\n"
     ]
    }
   ],
   "source": [
    "removelist = [k for k in userlist if len(userlist[k]) < 10]\n",
    "\n",
    "i=0\n",
    "itemset=set()\n",
    "print(len(userlist))\n",
    "for key in removelist:\n",
    "    del userlist[key]\n",
    "for k in userlist:    \n",
    "    userlist[k].sort(key = lambda x:x[1])\n",
    "#     print(userlist[k][:][0])\n",
    "    itemset = itemset.union(set([a for (a,b) in userlist[k]]))\n",
    "    \n",
    "print(len(userlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encodedict = {val:idx for idx,val in enumerate(list(itemset),start=1)}\n",
    "\n",
    "# print(encodedict)\n",
    "\n",
    "# featurevector = [[encodedict[x] for (x,y) in useritems] for useritems in userlist.values()]\n",
    "featurevector=[]\n",
    "maxlen = 0\n",
    "for userseq in userlist.values():\n",
    "#     featurevector.append([])\n",
    "    (featurevector.append([encodedict[x] for (x,y) in userseq]))\n",
    "    if len(featurevector[-1]) > maxlen:\n",
    "        maxlen = len(featurevector[-1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# the number of possible words in the vocabulary, here 1000 (1 + maximum word index),\n",
    "# and the dimensionality of the embeddings, here 32.\n",
    "embedding_dim=32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(featurevector,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 608 3290 4511 2484 1339 4464 4038 5214 4919 1967 6720    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mythri/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 125, 32)           220256    \n",
      "=================================================================\n",
      "Total params: 220,256\n",
      "Trainable params: 220,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layers.Embedding(len(itemset), embedding_dim, input_length=maxlen)\n",
    "  \n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
